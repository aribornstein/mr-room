<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <!-- Origin trial meta tag required for Quest 3 passthrough -->
    <meta http-equiv="origin-trial" content="Ahfj+MLeL6bh+LNmpnSdepftxoDHHwjUG2KWZ4jjCb1WoZxtBlzF3cDHuJNVqnhr3HXJwQ+kLaw57NO15S0mRwwAAABkeyJvcmlnaW4iOiJodHRwczovL2ltbWVyc2l2ZS13ZWIuZ2l0aHViLmlvOjQ0MyIsImZlYXR1cmUiOiJXZWJYUlBsYW5lRGV0ZWN0aW9uIiwiZXhwaXJ5IjoxNjI5ODQ5NTk5fQ==">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>AR with Depth-Sensing Occlusion Fallback</title>
    <style>
      body { margin: 0; overflow: hidden; background: none; }
      canvas { display: block; background: none; }
      #info {
        position: absolute;
        top: 10px;
        left: 10px;
        background: rgba(255,255,255,0.8);
        padding: 10px;
        font-family: sans-serif;
        z-index: 100;
      }
      #ar-button {
        position: absolute;
        bottom: 20px;
        left: 50%;
        transform: translateX(-50%);
        padding: 12px 24px;
        font-size: 16px;
        z-index: 100;
      }
    </style>
    <script type="importmap">
      {
        "imports": {
          "three": "https://unpkg.com/three@0.153.0/build/three.module.js"
        }
      }
    </script>
  </head>
  <body>
    <div id="info">
      Virtual Wallpaper Overlay<br>
      Room dimensions will be logged in the console.
    </div>
    <button id="ar-button">Enter AR</button>
    
    <script type="module">
      import * as THREE from 'https://unpkg.com/three@0.153.0/build/three.module.js';
      import { RealityAccelerator } from 'https://unpkg.com/ratk@0.3.0';

      if (!navigator.xr) {
        console.error("WebXR not available on this device/browser.");
        document.getElementById('info').innerText = "WebXR not available on this device/browser.";
      }
      
      // Create the renderer with a transparent background.
      const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      renderer.setClearColor(0x000000, 0); // fully transparent
      document.body.appendChild(renderer.domElement);
      
      // XRWebGLBinding will be created after the session starts.
      let xrGlBinding = null;

      // Fallback session creation: first try advanced config, then fallback.
      async function startARSession() {
        // Base configuration with required features.
        const baseConfig = {
          requiredFeatures: ['hit-test', 'plane-detection', 'anchors'],
          // Mark advanced features as optional.
          optionalFeatures: ['mesh-detection', 'depth-sensing']
        };
        // Advanced configuration: includes depth sensing preferences.
        const advancedConfig = {
          ...baseConfig,
          depthSensing: {
            usagePreference: ["cpu-optimized", "gpu-optimized"],
            dataFormatPreference: ["luminance-alpha", "float32"]
          }
        };

        try {
          // Attempt with advanced config.
          const session = await navigator.xr.requestSession('immersive-ar', advancedConfig);
          console.log("AR session started with advanced configuration.");
          return session;
        } catch (err) {
          console.warn("Advanced configuration failed, falling back.", err);
          try {
            const session = await navigator.xr.requestSession('immersive-ar', baseConfig);
            console.log("AR session started with base configuration.");
            return session;
          } catch (baseErr) {
            console.error("Failed to start AR session with base configuration.", baseErr);
            throw baseErr;
          }
        }
      }

      // AR button event: start session and create XRWebGLBinding.
      document.getElementById('ar-button').addEventListener('click', () => {
        startARSession().then(session => {
          renderer.xr.setReferenceSpaceType('local');
          renderer.xr.setSession(session);
          // Create XRWebGLBinding to access depth textures if available.
          const gl = renderer.getContext();
          try {
            xrGlBinding = new XRWebGLBinding(session, gl);
          } catch (error) {
            console.warn("XRWebGLBinding not available:", error);
          }
        }).catch(err => {
          console.error("Could not create an AR session.", err);
        });
      });
      
      // Set up scene, camera, and RATK.
      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.1, 1000);
      camera.position.set(0, 1.6, 0); // Typical eye level
      scene.add(camera);
      
      const ratk = new RealityAccelerator(renderer.xr);
      scene.add(ratk.root);
      
      // Texture Loader & Materials for surfaces.
      const textureLoader = new THREE.TextureLoader();
      const wallpaperTexture = textureLoader.load('https://threejs.org/examples/textures/brick_diffuse.jpg', () => {
        wallpaperTexture.wrapS = THREE.RepeatWrapping;
        wallpaperTexture.wrapT = THREE.RepeatWrapping;
      });
      const doorTexture = textureLoader.load('https://p7.hiclipart.com/preview/79/433/316/window-door-door.jpg', () => {
        doorTexture.wrapS = THREE.RepeatWrapping;
        doorTexture.wrapT = THREE.RepeatWrapping;
      });
      const windowTexture = textureLoader.load('https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSqEeF-9BcIAWiKTuiaDiwp0_ofJDfg6XkJww&s', () => {
        windowTexture.wrapS = THREE.RepeatWrapping;
        windowTexture.wrapT = THREE.RepeatWrapping;
      });
      const ceilingTexture = textureLoader.load('https://threejs.org/examples/textures/flower-1.jpg', () => {
        ceilingTexture.wrapS = THREE.RepeatWrapping;
        ceilingTexture.wrapT = THREE.RepeatWrapping;
      });
      
      function createMaterial(texture) {
        const material = new THREE.MeshBasicMaterial({
          map: texture,
          side: THREE.DoubleSide,
          transparent: true,
          opacity: 0.9,
          depthTest: true,
          depthWrite: false, // rely on occlusion pass for depth.
        });
        material.polygonOffset = true;
        material.polygonOffsetFactor = 1;
        material.polygonOffsetUnits = 1;
        return material;
      }
      
      const wallpaperMaterial = createMaterial(wallpaperTexture);
      const doorMaterial      = createMaterial(doorTexture);
      const windowMaterial    = createMaterial(windowTexture);
      const ceilingMaterial   = createMaterial(ceilingTexture);
      const passthroughMaterial = new THREE.MeshBasicMaterial({
        transparent: true,
        opacity: 0,
        side: THREE.DoubleSide,
        depthTest: false,
        depthWrite: false,
      });
      passthroughMaterial.colorWrite = false;
      
      function updateObjectMaterial(object, semanticLabel) {
        if (object && object.geometry) {
          const label = semanticLabel ? semanticLabel.toLowerCase() : "";
          let desiredMaterial = passthroughMaterial;
          if (label.includes("door")) {
            desiredMaterial = doorMaterial;
          } else if (label.includes("window")) {
            desiredMaterial = windowMaterial;
          } else if (label.includes("ceiling")) {
            desiredMaterial = ceilingMaterial;
          } else if (label.includes("wall") || label.includes("wall art")) {
            desiredMaterial = wallpaperMaterial;
          }
          if (object.material !== desiredMaterial) {
            object.material = desiredMaterial;
            object.renderOrder = (desiredMaterial === passthroughMaterial) ? -100 : 0;
            object.needsUpdate = true;
          }
        }
      }
      
      ratk.onPlaneAdded = (plane) => {
        console.log("New plane detected:", plane);
        if (plane.planeMesh) {
          updateObjectMaterial(plane.planeMesh, plane.semanticLabel);
        }
      };
      ratk.onPlaneUpdated = (plane) => {
        console.log("Plane updated:", plane);
        if (plane.planeMesh) {
          updateObjectMaterial(plane.planeMesh, plane.semanticLabel);
        }
      };
      ratk.onMeshAdded = (rmesh) => {
        console.log("New mesh detected:", rmesh);
        if (rmesh.meshMesh) {
          updateObjectMaterial(rmesh.meshMesh, rmesh.semanticLabel);
        }
        computeRoomBoundary();
      };
      
      function computeRoomBoundary() {
        const overallBox = new THREE.Box3();
        ratk.meshes.forEach(rmesh => {
          if (rmesh.meshMesh && rmesh.meshMesh.geometry) {
            rmesh.meshMesh.geometry.computeBoundingBox();
            const box = new THREE.Box3().setFromObject(rmesh.meshMesh);
            overallBox.union(box);
          }
        });
        const size = new THREE.Vector3();
        overallBox.getSize(size);
        console.log(`Room dimensions (meters): width: ${size.x.toFixed(2)}, height: ${size.y.toFixed(2)}, depth: ${size.z.toFixed(2)}`);
        return overallBox;
      }
      
      // --- Occlusion Pass using Depth-Sensing ---
      // We create a full-screen quad that uses the depth texture (if available)
      // to write to the depth buffer without drawing color.
      const occlusionGeometry = new THREE.PlaneGeometry(2, 2);
      const occlusionMaterial = new THREE.ShaderMaterial({
        uniforms: {
          u_DepthTexture: { value: null },
          u_UVTransform: { value: new THREE.Matrix4() },
          u_RawValueToMeters: { value: 1.0 }
        },
        vertexShader: `
          void main() {
            gl_Position = vec4(position, 1.0);
          }
        `,
        fragmentShader: `
          precision mediump float;
          uniform sampler2D u_DepthTexture;
          uniform mat4 u_UVTransform;
          uniform float u_RawValueToMeters;
          void main() {
            // Discard output; depth texture is used for occlusion only.
            discard;
          }
        `,
        depthWrite: true,
        depthTest: true,
        colorWrite: false
      });
      const occlusionMesh = new THREE.Mesh(occlusionGeometry, occlusionMaterial);
      occlusionMesh.renderOrder = -200; // Render first.
      scene.add(occlusionMesh);
      
      // Render loop.
      function render(timestamp, frame) {
        // Update occlusion mesh uniforms if depth-sensing is available.
        if (frame && xrGlBinding) {
          const referenceSpace = renderer.xr.getReferenceSpace();
          const viewerPose = frame.getViewerPose(referenceSpace);
          if (viewerPose) {
            const view = viewerPose.views[0];
            const depthInfo = xrGlBinding.getDepthInformation(view);
            if (depthInfo) {
              occlusionMaterial.uniforms.u_DepthTexture.value = depthInfo.texture;
              occlusionMaterial.uniforms.u_UVTransform.value.fromArray(depthInfo.normDepthBufferFromNormView.matrix);
              occlusionMaterial.uniforms.u_RawValueToMeters.value = depthInfo.rawValueToMeters;
            }
          }
        }
        ratk.update();
        renderer.render(scene, camera);
      }
      renderer.setAnimationLoop(render);
      
      window.addEventListener('resize', () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    </script>
  </body>
</html>
